import json
import os
from datetime import datetime
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
import torch
from datasets import Dataset

def load_summarization_model():
    """
    åŠ è½½ç”¨äºæ€»ç»“çš„è½»é‡çº§æ¨¡å‹
    """
    # å°è¯•ä¸åŒçš„è½»é‡çº§æ€»ç»“æ¨¡å‹
    models_to_try = [
        "Qwen/Qwen2.5-0.5B-Instruct",        # QwenæŒ‡ä»¤æ¨¡å‹ï¼Œé€‚åˆé—®é¢˜å¯¼å‘æ€»ç»“
        "sshleifer/distilbart-cnn-12-6",     # è½»é‡çº§ç‰ˆæœ¬ï¼Œä¼˜å…ˆä½¿ç”¨
        "t5-small",                          # éå¸¸è½»é‡
        "facebook/bart-large-cnn",           # é«˜è´¨é‡ä½†è¾ƒå¤§
        "google/pegasus-xsum",               # ä¸“é—¨ç”¨äºæ‘˜è¦
    ]
    
    for model_name in models_to_try:
        try:
            print(f"æ­£åœ¨å°è¯•åŠ è½½æ¨¡å‹: {model_name}")
            
            if "qwen" in model_name.lower():
                # Qwenæ¨¡å‹éœ€è¦ç‰¹æ®Šå¤„ç†
                summarizer = pipeline(
                    "text-generation",
                    model=model_name,
                    device=0 if torch.cuda.is_available() else -1,
                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                    trust_remote_code=True,  # Qwenæ¨¡å‹éœ€è¦è¿™ä¸ªå‚æ•°
                    batch_size=4  # Qwenæ¨¡å‹ä½¿ç”¨è¾ƒå°çš„æ‰¹å¤„ç†
                )
            elif "t5" in model_name.lower():
                # T5æ¨¡å‹éœ€è¦ç‰¹æ®Šå¤„ç†
                tokenizer = AutoTokenizer.from_pretrained(model_name)
                model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
                summarizer = pipeline(
                    "summarization",
                    model=model,
                    tokenizer=tokenizer,
                    device=0 if torch.cuda.is_available() else -1,
                    batch_size=8  # æ‰¹å¤„ç†å¤§å°
                )
            else:
                # å…¶ä»–æ¨¡å‹ä½¿ç”¨pipelineç›´æ¥åŠ è½½
                summarizer = pipeline(
                    "summarization",
                    model=model_name,
                    device=0 if torch.cuda.is_available() else -1,
                    batch_size=8  # æ‰¹å¤„ç†å¤§å°
                )
            
            print(f"æˆåŠŸåŠ è½½æ¨¡å‹: {model_name}")
            return summarizer, model_name
            
        except Exception as e:
            print(f"æ¨¡å‹ {model_name} åŠ è½½å¤±è´¥: {e}")
            continue
    
    # å¦‚æœæ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
    print("ä½¿ç”¨å¤‡ç”¨çš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹è¿›è¡Œæ€»ç»“...")
    try:
        summarizer = pipeline(
            "text-generation",
            model="gpt2",
            device=0 if torch.cuda.is_available() else -1,
            batch_size=8
        )
        return summarizer, "gpt2-fallback"
    except Exception as e:
        print(f"å¤‡ç”¨æ¨¡å‹ä¹ŸåŠ è½½å¤±è´¥: {e}")
        return None, None

def generate_summary_with_qwen(question, text, summarizer):
    """
    ä½¿ç”¨Qwenæ¨¡å‹ç”Ÿæˆé’ˆå¯¹é—®é¢˜çš„æ€»ç»“
    """
    try:
        # æ„å»ºQwenæ ¼å¼çš„æ¶ˆæ¯ï¼Œä¸“é—¨ç”¨äºæ€»ç»“
        messages = [
            {
                "role": "user", 
                "content": f"""Based on the following context, create a focused summary that contains information specifically relevant to answering the question. 

Question: {question}

Context: {text}

Please provide a concise summary (50-100 words) that highlights the key information needed to answer the question. Focus on facts, dates, names, and relationships mentioned in the context:"""
            }
        ]
        
        response = summarizer(
            messages,
            max_new_tokens=200,  # ç»™æ€»ç»“è¶³å¤Ÿçš„ç©ºé—´
            num_return_sequences=1,
            temperature=0.3,  # è¾ƒä½æ¸©åº¦è·å¾—æ›´èšç„¦çš„æ€»ç»“
            do_sample=True,
            pad_token_id=summarizer.tokenizer.eos_token_id,
            eos_token_id=summarizer.tokenizer.eos_token_id
        )
        
        print(f"Debug - Qwenæ€»ç»“åŸå§‹å“åº”: {response}")  # è°ƒè¯•ä¿¡æ¯
        
        # æå–ç”Ÿæˆçš„å†…å®¹
        summary = ""
        if isinstance(response, list) and len(response) > 0:
            generated_text = response[0].get('generated_text', '')
            
            # å¦‚æœè¿”å›çš„æ˜¯æ¶ˆæ¯æ ¼å¼
            if isinstance(generated_text, list) and len(generated_text) > 1:
                # è·å–åŠ©æ‰‹çš„å›å¤
                assistant_reply = generated_text[-1].get('content', '')
                summary = assistant_reply.strip()
            else:
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼Œç›´æ¥å¤„ç†
                summary = str(generated_text).strip()
        
        # å¤„ç†Qwençš„ç‰¹æ®Šæ ‡è®°ï¼Œå‚è€ƒanswer.pyçš„å¤„ç†é€»è¾‘
        if summary:
            import re
            
            # å¤„ç†<think>æ ‡è®°
            if "<think>" in summary:
                if "</think>" in summary:
                    # æå–</think>åçš„å†…å®¹ä½œä¸ºæœ€ç»ˆæ€»ç»“
                    summary = summary.split("</think>")[-1].strip()
                else:
                    # å¦‚æœæ²¡æœ‰é—­åˆæ ‡ç­¾ï¼Œå°è¯•ä»<think>åæå–æ€»ç»“
                    think_part = summary.split("<think>")[-1]
                    # æŸ¥æ‰¾æ€»ç»“å†…å®¹
                    lines = think_part.split('\n')
                    summary_lines = []
                    for line in lines:
                        line = line.strip()
                        # è·³è¿‡æ˜æ˜¾çš„æ€è€ƒè¿‡ç¨‹è¡Œ
                        if line and not line.lower().startswith(('let me', 'i need to', 'looking at', 'the question', 'based on')):
                            # å¯»æ‰¾åŒ…å«å®é™…ä¿¡æ¯çš„è¡Œ
                            if any(word in line.lower() for word in ['magazine', 'published', 'started', 'founded', 'year']):
                                summary_lines.append(line)
                    
                    if summary_lines:
                        summary = ' '.join(summary_lines[:3])  # æœ€å¤š3è¡Œ
                    else:
                        # å¦‚æœæ²¡æ‰¾åˆ°åˆé€‚çš„è¡Œï¼Œä½¿ç”¨å…³é”®ä¿¡æ¯æå–
                        return extract_key_info_for_question(question, text)
            
            # æ¸…ç†æ€»ç»“ä¸­çš„å¤šä½™å†…å®¹
            if "Context:" in summary:
                summary = summary.split("Context:")[-1]
            if "Question:" in summary:
                summary = summary.split("Question:")[-1]
            if "Summary:" in summary:
                summary = summary.split("Summary:")[-1].strip()
            
            # ç§»é™¤å¸¸è§çš„æ€»ç»“å‰ç¼€
            prefixes_to_remove = [
                "Here is a summary", "Here's a summary", "The summary is", 
                "Based on the context", "According to", "The key information"
            ]
            for prefix in prefixes_to_remove:
                if summary.lower().startswith(prefix.lower()):
                    summary = summary[len(prefix):].strip()
                    if summary.startswith(":"):
                        summary = summary[1:].strip()
                    break
            
            # æ¸…ç†æ ¼å¼
            summary = summary.replace('\\n', ' ').replace('\n', ' ')
            summary = ' '.join(summary.split())  # æ ‡å‡†åŒ–ç©ºæ ¼
            
            # ç¡®ä¿æ€»ç»“é•¿åº¦åˆé€‚
            words = summary.split()
            if len(words) > 200:  # å¦‚æœå¤ªé•¿ï¼Œæˆªå–åˆ°80è¯
                summary = ' '.join(words[:200]) + "..."
            elif len(words) < 10:  # å¦‚æœå¤ªçŸ­ï¼Œå¯èƒ½è´¨é‡ä¸å¥½
                print(f"Debug - Qwenæ€»ç»“å¤ªçŸ­: '{summary}', ä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
                return extract_key_info_for_question(question, text)
            
            print(f"Debug - Qwenæœ€ç»ˆæ€»ç»“: '{summary}'")
            
            return summary.strip()
        
        # å¦‚æœæ²¡æœ‰è·å¾—æœ‰æ•ˆæ€»ç»“ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•
        return extract_key_info_for_question(question, text)
        
    except Exception as e:
        print(f"Qwenç”Ÿæˆæ€»ç»“æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        # å¦‚æœå‡ºé”™ï¼Œä½¿ç”¨å…³é”®ä¿¡æ¯æå–
        return extract_key_info_for_question(question, text)

def generate_summary_with_qwen_fallback(question, text, summarizer):
    """
    Qwenæ¨¡å‹çš„å¤‡ç”¨æ€»ç»“æ–¹æ¡ˆ
    """
    try:
        # ä½¿ç”¨æ›´ç®€å•çš„promptæ ¼å¼
        prompt = f"""Question: {question}

Context: {text}

Create a brief summary focusing on information relevant to the question:"""
        
        response = summarizer(
            prompt,
            max_new_tokens=120,
            num_return_sequences=1,
            temperature=0.3,
            do_sample=True,
            pad_token_id=summarizer.tokenizer.eos_token_id,
            eos_token_id=summarizer.tokenizer.eos_token_id
        )
        
        generated_text = response[0]['generated_text']
        
        # æå–æ€»ç»“éƒ¨åˆ†
        if "Create a brief summary" in generated_text:
            summary = generated_text.split("Create a brief summary")[-1]
            if ":" in summary:
                summary = summary.split(":", 1)[1].strip()
        else:
            summary = generated_text.replace(prompt, "").strip()
        
        # å¤„ç†thinkæ ‡è®°
        import re
        if "<think>" in summary:
            if "</think>" in summary:
                summary = summary.split("</think>")[-1].strip()
            else:
                # ä»thinkå†…å®¹ä¸­æå–å…³é”®ä¿¡æ¯
                think_content = summary.split("<think>")[-1]
                lines = think_content.split('\n')
                for line in lines:
                    line = line.strip()
                    if line and len(line.split()) > 5 and len(line.split()) < 30:
                        summary = line
                        break
                else:
                    return extract_key_info_for_question(question, text)
        
        # æ¸…ç†æ€»ç»“
        summary = summary.split('\n')[0].strip()
        summary = re.sub(r'\([^)]*\)', '', summary).strip()
        
        words = summary.split()
        if len(words) > 60:
            summary = " ".join(words[:60]) + "..."
        
        print(f"Debug - Qwenå¤‡ç”¨æ€»ç»“: '{summary}'")
        
        return summary if summary else extract_key_info_for_question(question, text)
        
    except Exception as e:
        print(f"Qwenå¤‡ç”¨æ€»ç»“æ–¹æ¡ˆå¤±è´¥: {e}")
        return extract_key_info_for_question(question, text)

def generate_summaries_batch(batch_inputs, summarizer, model_name, batch_size=8):
    """
    æ‰¹é‡ç”Ÿæˆé’ˆå¯¹é—®é¢˜çš„æ€»ç»“ï¼Œå¹¶è¾“å‡ºå®æ—¶è¿›åº¦
    """
    if not batch_inputs or not summarizer:
        return []
    
    summaries = []
    
    try:
        print(f"\n{'='*60}")
        print(f"å¼€å§‹æ‰¹é‡ç”Ÿæˆæ€»ç»“")
        print(f"æ€»é—®é¢˜æ•°: {len(batch_inputs)}")
        print(f"æ‰¹å¤„ç†å¤§å°: {batch_size}")
        print(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
        print(f"{'='*60}")
        
        if "qwen" in model_name.lower():
            # Qwenæ¨¡å‹å¤„ç†ï¼Œé€ä¸ªå¤„ç†ä»¥ç¡®ä¿è´¨é‡
            print("ğŸ“ ä½¿ç”¨Qwenæ¨¡å‹é€ä¸ªå¤„ç†...")
            for idx, item in enumerate(batch_inputs):
                question = item['question']
                text = item['text']
                
                print(f"ğŸ”„ å¤„ç†ç¬¬ {idx + 1}/{len(batch_inputs)} ä¸ªé—®é¢˜...")
                print(f"   é—®é¢˜: {question[:80]}...")
                
                # ä½¿ç”¨ä¸»è¦çš„Qwenæ€»ç»“æ–¹æ³•
                summary = generate_summary_with_qwen(question, text, summarizer)
                
                # å¦‚æœä¸»è¦æ–¹æ³•å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
                if not summary or len(summary.strip()) < 10:
                    print("   ğŸ”„ ä¸»è¦æ–¹æ³•ç»“æœä¸ä½³ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•...")
                    summary = generate_summary_with_qwen_fallback(question, text, summarizer)
                
                summaries.append(summary)
                
                print(f"   âœ… ç”Ÿæˆæ€»ç»“: {summary[:100]}...")
                
                # æ¯å¤„ç†5ä¸ªæ˜¾ç¤ºè¿›åº¦
                if (idx + 1) % 5 == 0 or (idx + 1) == len(batch_inputs):
                    progress = (idx + 1) / len(batch_inputs) * 100
                    print(f"ğŸ“Š Qwenå¤„ç†è¿›åº¦: {idx + 1}/{len(batch_inputs)} ({progress:.1f}%)")
                    print("-" * 40)
        
        elif "gpt2-fallback" in model_name:
            # GPT2å¤‡ç”¨æ–¹æ¡ˆï¼Œé€ä¸ªå¤„ç†
            print("ğŸ“ ä½¿ç”¨GPT2å¤‡ç”¨æ–¹æ¡ˆï¼Œé€ä¸ªå¤„ç†...")
            for idx, item in enumerate(batch_inputs):
                question = item['question']
                text = item['text']
                summary = generate_question_focused_summary(question, [text], summarizer, model_name)
                summaries.append(summary)
                
                # æ¯å¤„ç†1ä¸ªå°±æ˜¾ç¤ºè¿›åº¦
                if (idx + 1) % 1 == 0:
                    progress = (idx + 1) / len(batch_inputs) * 100
                    print(f"ğŸ”„ ç¬¬ {idx + 1}/{len(batch_inputs)} ä¸ªæ€»ç»“å®Œæˆ ({progress:.1f}%) - {summary[:50]}...")
        
        elif "t5" in model_name.lower():
            # T5æ¨¡å‹åˆ†æ‰¹å¤„ç†ï¼Œæ”¹è¿›prompt
            print("ğŸ¤– ä½¿ç”¨T5æ¨¡å‹åˆ†æ‰¹å¤„ç†...")
            
            # å‡†å¤‡è¾“å…¥æ•°æ® - æ”¹è¿›promptè®¾è®¡
            print("å‡†å¤‡è¾“å…¥æ•°æ®...")
            input_texts = []
            for idx, item in enumerate(batch_inputs):
                # æ”¹è¿›çš„promptï¼Œæ›´æ˜ç¡®åœ°æŒ‡å‘é—®é¢˜
                question = item['question']
                text = item['text']
                
                # æ ¹æ®é—®é¢˜ç±»å‹è®¾è®¡ä¸åŒçš„prompt
                if "which" in question.lower() and ("first" in question.lower() or "started" in question.lower()):
                    # å¯¹äºæ¯”è¾ƒç±»é—®é¢˜ï¼Œå¼ºè°ƒæ—¶é—´æ¯”è¾ƒ
                    input_text = f"Compare the start dates mentioned in the text to answer: {question}. Context: {text}"
                elif "when" in question.lower():
                    input_text = f"Extract dates and timeline information to answer: {question}. Context: {text}"
                elif "who" in question.lower():
                    input_text = f"Identify people and their roles to answer: {question}. Context: {text}"
                else:
                    input_text = f"Extract key information specifically relevant to: {question}. Context: {text}"
                
                input_texts.append(input_text)
                
                if (idx + 1) % 100 == 0:
                    print(f"   è¾“å…¥å‡†å¤‡è¿›åº¦: {idx + 1}/{len(batch_inputs)}")
            
            print(f"âœ… è¾“å…¥æ•°æ®å‡†å¤‡å®Œæˆï¼Œå¼€å§‹åˆ†æ‰¹æ¨ç†...")
            
            # åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹éƒ½æ˜¾ç¤ºè¿›åº¦
            total_batches = (len(input_texts) + batch_size - 1) // batch_size
            
            for batch_idx in range(0, len(input_texts), batch_size):
                end_idx = min(batch_idx + batch_size, len(input_texts))
                batch_texts = input_texts[batch_idx:end_idx]
                current_batch_num = batch_idx // batch_size + 1
                
                print(f"ğŸ”„ å¤„ç†ç¬¬ {current_batch_num}/{total_batches} æ‰¹ (é¡¹ç›® {batch_idx+1}-{end_idx})...")
                
                try:
                    # å¤„ç†å½“å‰æ‰¹æ¬¡
                    batch_results = summarizer(
                        batch_texts,
                        max_length=120,
                        min_length=20,
                        do_sample=False
                    )
                    
                    # æå–æ€»ç»“å¹¶æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                    batch_summaries = [result['summary_text'] for result in batch_results]
                    summaries.extend(batch_summaries)
                    
                    # æ˜¾ç¤ºå½“å‰æ‰¹æ¬¡çš„ç»“æœç¤ºä¾‹
                    if batch_summaries:
                        print(f"   âœ… æ‰¹æ¬¡ {current_batch_num} å®Œæˆï¼Œç¤ºä¾‹: {batch_summaries[0][:60]}...")
                    
                    # æ˜¾ç¤ºæ€»ä½“è¿›åº¦
                    overall_progress = len(summaries) / len(input_texts) * 100
                    print(f"   ğŸ“Š æ€»ä½“è¿›åº¦: {len(summaries)}/{len(input_texts)} ({overall_progress:.1f}%)")
                    
                except Exception as e:
                    print(f"   âŒ æ‰¹æ¬¡ {current_batch_num} å¤„ç†å¤±è´¥: {e}")
                    # ä¸ºå¤±è´¥çš„æ‰¹æ¬¡æ·»åŠ ç©ºæ€»ç»“
                    summaries.extend([""] * len(batch_texts))
            
            print(f"âœ… T5æ¨¡å‹åˆ†æ‰¹å¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(summaries)} ä¸ªæ€»ç»“")
        
        else:
            # æ ‡å‡†æ€»ç»“æ¨¡å‹åˆ†æ‰¹å¤„ç† - æ”¹è¿›prompt
            print(f"ğŸ“Š ä½¿ç”¨æ ‡å‡†æ€»ç»“æ¨¡å‹åˆ†æ‰¹å¤„ç†...")
            
            # å‡†å¤‡è¾“å…¥æ•°æ® - æ”¹è¿›promptè®¾è®¡
            print("å‡†å¤‡è¾“å…¥æ•°æ®...")
            input_texts = []
            for idx, item in enumerate(batch_inputs):
                question = item['question']
                text = item['text']
                
                # æ”¹è¿›çš„promptè®¾è®¡ï¼Œæ›´èšç„¦äºé—®é¢˜
                if "which" in question.lower() and ("first" in question.lower() or "started" in question.lower()):
                    # å¯¹äºæ¯”è¾ƒç±»é—®é¢˜ï¼Œå¼ºè°ƒæ‰¾å‡ºä¸¤ä¸ªå®ä½“çš„å¼€å§‹æ—¶é—´
                    input_text = f"Question asks which started first. Find the start dates of each mentioned entity. Question: {question}. Information: {text}"
                elif "when" in question.lower():
                    input_text = f"Question asks about timing. Extract all dates and time information. Question: {question}. Information: {text}"
                elif "who" in question.lower():
                    input_text = f"Question asks about people. Identify all people mentioned and their roles. Question: {question}. Information: {text}"
                elif "where" in question.lower():
                    input_text = f"Question asks about location. Extract all places and locations mentioned. Question: {question}. Information: {text}"
                elif "what" in question.lower():
                    input_text = f"Question asks for definition or description. Extract key characteristics and descriptions. Question: {question}. Information: {text}"
                else:
                    input_text = f"Extract information specifically needed to answer this question: {question}. Available information: {text}"
                
                # é™åˆ¶è¾“å…¥é•¿åº¦
                if len(input_text) > 1000:
                    input_text = input_text[:1000]
                input_texts.append(input_text)
                
                if (idx + 1) % 100 == 0:
                    print(f"   è¾“å…¥å‡†å¤‡è¿›åº¦: {idx + 1}/{len(batch_inputs)}")
            
            print(f"âœ… è¾“å…¥æ•°æ®å‡†å¤‡å®Œæˆï¼Œå¼€å§‹åˆ†æ‰¹æ¨ç†...")
            
            # åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹éƒ½æ˜¾ç¤ºè¿›åº¦
            total_batches = (len(input_texts) + batch_size - 1) // batch_size
            
            for batch_idx in range(0, len(input_texts), batch_size):
                end_idx = min(batch_idx + batch_size, len(input_texts))
                batch_texts = input_texts[batch_idx:end_idx]
                current_batch_num = batch_idx // batch_size + 1
                
                print(f"ğŸ”„ å¤„ç†ç¬¬ {current_batch_num}/{total_batches} æ‰¹ (é¡¹ç›® {batch_idx+1}-{end_idx})...")
                
                try:
                    # å¤„ç†å½“å‰æ‰¹æ¬¡
                    batch_results = summarizer(
                        batch_texts,
                        max_length=150,  # ç¨å¾®å¢åŠ é•¿åº¦ä»¥å®¹çº³æ¯”è¾ƒä¿¡æ¯
                        min_length=30,
                        do_sample=False
                    )
                    
                    # æå–æ€»ç»“å¹¶æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                    batch_summaries = [result['summary_text'] for result in batch_results]
                    summaries.extend(batch_summaries)
                    
                    # æ˜¾ç¤ºå½“å‰æ‰¹æ¬¡çš„ç»“æœç¤ºä¾‹
                    if batch_summaries:
                        print(f"   âœ… æ‰¹æ¬¡ {current_batch_num} å®Œæˆï¼Œç¤ºä¾‹: {batch_summaries[0][:80]}...")
                    
                    # æ˜¾ç¤ºæ€»ä½“è¿›åº¦
                    overall_progress = len(summaries) / len(input_texts) * 100
                    print(f"   ğŸ“Š æ€»ä½“è¿›åº¦: {len(summaries)}/{len(input_texts)} ({overall_progress:.1f}%)")
                    print(f"   â±ï¸  å·²å®Œæˆ {len(summaries)} ä¸ªæ€»ç»“")
                    
                    # æ¯å®Œæˆå‡ ä¸ªæ‰¹æ¬¡æ˜¾ç¤ºæ›´è¯¦ç»†çš„ä¿¡æ¯
                    if current_batch_num % 5 == 0:
                        print(f"   ğŸ¯ é‡Œç¨‹ç¢‘: å·²å®Œæˆ {current_batch_num} ä¸ªæ‰¹æ¬¡ï¼Œç»§ç»­å¤„ç†...")
                        print(f"   ğŸ“ˆ æ•ˆç‡: å¹³å‡æ¯æ‰¹å¤„ç† {len(batch_summaries)} ä¸ªé¡¹ç›®")
                        print("-" * 40)
                    
                except Exception as e:
                    print(f"   âŒ æ‰¹æ¬¡ {current_batch_num} å¤„ç†å¤±è´¥: {e}")
                    # å°è¯•å•ä¸ªå¤„ç†è¿™ä¸ªæ‰¹æ¬¡
                    print(f"   ğŸ”„ å°è¯•å•ä¸ªå¤„ç†æ‰¹æ¬¡ {current_batch_num}...")
                    batch_summaries = []
                    for single_text in batch_texts:
                        try:
                            single_result = summarizer(
                                single_text,
                                max_length=150,
                                min_length=30,
                                do_sample=False
                            )
                            batch_summaries.append(single_result[0]['summary_text'])
                        except:
                            batch_summaries.append("")
                    
                    summaries.extend(batch_summaries)
                    print(f"   âœ… æ‰¹æ¬¡ {current_batch_num} å•ä¸ªå¤„ç†å®Œæˆ")
            
            print(f"âœ… æ ‡å‡†æ¨¡å‹åˆ†æ‰¹å¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(summaries)} ä¸ªæ€»ç»“")
        
        # æ¸…ç†å’ŒéªŒè¯æ€»ç»“ï¼ˆä¹Ÿæ˜¾ç¤ºè¿›åº¦ï¼‰
        print(f"\n{'='*40}")
        print("ğŸ§¹ å¼€å§‹æ¸…ç†å’ŒéªŒè¯æ€»ç»“...")
        print(f"{'='*40}")
        
        cleaned_summaries = []
        poor_quality_count = 0
        
        for i, summary in enumerate(summaries):
            summary = summary.strip()
            
            # å¦‚æœæ€»ç»“è´¨é‡ä¸å¥½ï¼Œä½¿ç”¨å…³é”®ä¿¡æ¯æå–
            if len(summary) < 10 or summary.lower().startswith(("the", "this", "it")):
                question = batch_inputs[i]['question']
                text = batch_inputs[i]['text']
                summary = extract_key_info_for_question(question, text)
                poor_quality_count += 1
                
                if poor_quality_count <= 3:  # åªæ˜¾ç¤ºå‰3ä¸ªè´¨é‡é—®é¢˜
                    print(f"âš ï¸  ç¬¬{i+1}ä¸ªæ€»ç»“è´¨é‡ä¸ä½³ï¼Œä½¿ç”¨å…³é”®ä¿¡æ¯æå–")
            
            cleaned_summaries.append(summary)
            
            # æ¯å¤„ç†å®Œ50æ¡æ˜¾ç¤ºä¸€æ¬¡æ¸…ç†è¿›åº¦
            if (i + 1) % 50 == 0 or (i + 1) == len(summaries):
                progress = (i + 1) / len(summaries) * 100
                print(f"ğŸ§¹ æ¸…ç†è¿›åº¦: {i + 1}/{len(summaries)} ({progress:.1f}%)")
        
        print(f"\n{'='*50}")
        print(f"âœ… æ€»ç»“ç”Ÿæˆå®Œæˆï¼")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - æ€»é—®é¢˜æ•°: {len(batch_inputs)}")
        print(f"   - æˆåŠŸç”Ÿæˆ: {len(cleaned_summaries)}")
        print(f"   - è´¨é‡é—®é¢˜: {poor_quality_count}")
        print(f"   - æˆåŠŸç‡: {(len(cleaned_summaries)-poor_quality_count)/len(cleaned_summaries)*100:.1f}%")
        print(f"{'='*50}")
        
        return cleaned_summaries
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡ç”Ÿæˆé—®é¢˜å¯¼å‘æ€»ç»“æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        
        # é™çº§åˆ°é€ä¸ªå¤„ç†ï¼ˆæ˜¾ç¤ºæ¯ä¸ªå¤„ç†è¿›åº¦ï¼‰
        print(f"\n{'='*40}")
        print("ğŸ†˜ é™çº§åˆ°é€ä¸ªå¤„ç†æ¨¡å¼...")
        print(f"{'='*40}")
        
        summaries = []
        error_count = 0
        
        for idx, item in enumerate(batch_inputs):
            try:
                question = item['question']
                text = item['text']
                summary = extract_key_info_for_question(question, text)
                summaries.append(summary)
                
                # æ¯ä¸ªéƒ½æ˜¾ç¤ºè¿›åº¦
                progress = (idx + 1) / len(batch_inputs) * 100
                print(f"ğŸ”„ é™çº§æ¨¡å¼: {idx + 1}/{len(batch_inputs)} ({progress:.1f}%) - {summary[:40]}...")
                
                # æ¯10ä¸ªæ˜¾ç¤ºä¸€ä¸ªé‡Œç¨‹ç¢‘
                if (idx + 1) % 10 == 0:
                    print(f"ğŸ“ˆ é‡Œç¨‹ç¢‘: å·²å®Œæˆ {idx + 1} ä¸ªï¼Œç»§ç»­å¤„ç†...")
                    
            except Exception as e2:
                error_count += 1
                print(f"âŒ å¤„ç†ç¬¬{idx+1}ä¸ªé—®é¢˜æ—¶å‡ºé”™: {e2}")
                summaries.append("")
        
        print(f"\n{'='*40}")
        print(f"âœ… é™çº§æ¨¡å¼å®Œæˆ")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - å¤„ç†æ€»æ•°: {len(batch_inputs)}")
        print(f"   - æˆåŠŸå¤„ç†: {len(summaries) - error_count}")
        print(f"   - é”™è¯¯æ•°é‡: {error_count}")
        print(f"   - æˆåŠŸç‡: {(len(summaries) - error_count)/len(summaries)*100:.1f}%")
        print(f"{'='*40}")
        
        return summaries

def extract_key_info_for_question(question, text):
    """
    åŸºäºé—®é¢˜ç±»å‹æå–å…³é”®ä¿¡æ¯ä½œä¸ºæ€»ç»“
    """
    import re
    
    question_lower = question.lower()
    
    # ç‰¹åˆ«å¤„ç†æ¯”è¾ƒç±»é—®é¢˜
    if "which" in question_lower and ("first" in question_lower or "started" in question_lower):
        # æå–æ‰€æœ‰å¹´ä»½å’Œå®ä½“
        sentences = text.split('.')
        relevant_info = []
        
        # æŸ¥æ‰¾å¹´ä»½ä¿¡æ¯
        for sentence in sentences:
            # æŸ¥æ‰¾å››ä½æ•°å¹´ä»½
            years = re.findall(r'\b(1[89]\d{2}|20\d{2})\b', sentence)
            if years:
                relevant_info.append(sentence.strip())
        
        # å¦‚æœæ‰¾åˆ°æ—¶é—´ä¿¡æ¯ï¼Œè¿”å›è¿™äº›å¥å­
        if relevant_info:
            summary = '. '.join(relevant_info[:3])  # æœ€å¤šä¸‰å¥
        else:
            # å¦‚æœæ²¡æ‰¾åˆ°æ˜ç¡®å¹´ä»½ï¼ŒæŸ¥æ‰¾åŒ…å«"started"ã€"founded"ã€"began"ç­‰è¯çš„å¥å­
            for sentence in sentences:
                if any(word in sentence.lower() for word in ['started', 'founded', 'began', 'established', 'published']):
                    relevant_info.append(sentence.strip())
            summary = '. '.join(relevant_info[:2])
    
    elif "who" in question_lower:
        # æå–äººåç›¸å…³çš„å¥å­
        sentences = text.split('.')
        relevant_sentences = []
        for sentence in sentences:
            if any(word[0].isupper() and len(word) > 2 for word in sentence.split()):
                relevant_sentences.append(sentence.strip())
        summary = '. '.join(relevant_sentences[:2])
    
    elif "when" in question_lower or "year" in question_lower:
        # æå–åŒ…å«æ—¶é—´ä¿¡æ¯çš„å¥å­
        sentences = text.split('.')
        relevant_sentences = []
        for sentence in sentences:
            if re.search(r'\b(19|20)\d{2}\b|\b(January|February|March|April|May|June|July|August|September|October|November|December)\b', sentence):
                relevant_sentences.append(sentence.strip())
        summary = '. '.join(relevant_sentences[:2])
    
    elif "where" in question_lower or "city" in question_lower or "country" in question_lower:
        # æå–åœ°ç‚¹ç›¸å…³ä¿¡æ¯
        sentences = text.split('.')
        relevant_sentences = []
        for sentence in sentences:
            # å¯»æ‰¾åœ°ç‚¹æ ‡è¯†è¯
            location_words = ['in', 'at', 'from', 'city', 'country', 'located', 'based']
            if any(word in sentence.lower() for word in location_words):
                relevant_sentences.append(sentence.strip())
        summary = '. '.join(relevant_sentences[:2])
    
    elif "what" in question_lower:
        # æå–åŒ…å«å®šä¹‰æˆ–æè¿°çš„å¥å­
        sentences = text.split('.')
        relevant_sentences = []
        for sentence in sentences:
            # å¯»æ‰¾å®šä¹‰æ€§è¯æ±‡
            definition_words = ['is', 'was', 'are', 'were', 'means', 'refers', 'describes']
            if any(word in sentence.lower().split() for word in definition_words):
                relevant_sentences.append(sentence.strip())
        summary = '. '.join(relevant_sentences[:2])
    
    else:
        # é»˜è®¤æƒ…å†µï¼šå–å‰ä¸¤å¥
        sentences = text.split('.')
        summary = '. '.join(sentences[:2])
    
    # é™åˆ¶é•¿åº¦
    if len(summary) > 300:
        summary = summary[:300] + "..."
    
    return summary.strip() if summary.strip() else text[:200]

def prepare_batch_data(data_list, max_input_length=800):
    """
    å‡†å¤‡æ‰¹å¤„ç†æ•°æ®ï¼ŒåŒ…å«é—®é¢˜ä¿¡æ¯
    """
    batch_inputs = []
    indices = []
    
    for i, data in enumerate(data_list):
        question = data.get('question', '')
        related = data.get('related', [])
        
        if related and question:
            # åˆå¹¶ç›¸å…³æ®µè½
            combined_text = " ".join(related).strip()
            
            # é™åˆ¶è¾“å…¥é•¿åº¦
            if len(combined_text) > max_input_length:
                combined_text = combined_text[:max_input_length]
            
            batch_inputs.append({
                'question': question,
                'text': combined_text
            })
            indices.append(i)
    
    return batch_inputs, indices


def process_extraction_file(input_file, batch_size=16):
    """
    å¤„ç†æå–æ–‡ä»¶ï¼Œä¸ºæ¯è¡Œæ·»åŠ åŸºäºé—®é¢˜çš„summaryå­—æ®µ
    """
    # åŠ è½½æ€»ç»“æ¨¡å‹
    print("æ­£åœ¨åŠ è½½æ€»ç»“æ¨¡å‹...")
    summarizer, model_name = load_summarization_model()
    
    if not summarizer:
        print("æ— æ³•åŠ è½½ä»»ä½•æ¨¡å‹ï¼Œé€€å‡ºç¨‹åº")
        return
    
    print(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
    print(f"æ‰¹å¤„ç†å¤§å°: {batch_size}")
    print("æ¨¡å¼: åŸºäºé—®é¢˜ç”Ÿæˆé’ˆå¯¹æ€§æ€»ç»“")
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d")
    input_filename = os.path.basename(input_file)
    output_filename = f"{timestamp}_summary_{input_filename}"
    output_dir = "/home/xhesica/research/outputs"
    output_file = os.path.join(output_dir, output_filename)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        # è¯»å–æ‰€æœ‰æ•°æ®
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # è§£æJSONæ•°æ®
        data_list = []
        for i, line in enumerate(lines):
            line = line.strip()
            if line:
                try:
                    data = json.loads(line)
                    data_list.append(data)
                except json.JSONDecodeError as e:
                    print(f"ç¬¬{i+1}è¡ŒJSONè§£æé”™è¯¯: {e}")
                    continue
        
        total_items = len(data_list)
        print(f"æˆåŠŸè§£æ {total_items} æ¡è®°å½•ï¼Œå¼€å§‹æ‰¹é‡å¤„ç†...")
        
        # å‡†å¤‡æ‰¹å¤„ç†æ•°æ®
        batch_inputs, indices = prepare_batch_data(data_list)
        
        if not batch_inputs:
            print("æ²¡æœ‰æ‰¾åˆ°åŒ…å«é—®é¢˜å’Œç›¸å…³æ–‡æœ¬çš„è®°å½•")
            return
        
        print(f"å‡†å¤‡ä¸º {len(batch_inputs)} ä¸ªé—®é¢˜ç”Ÿæˆé’ˆå¯¹æ€§æ€»ç»“...")
        
        # æ‰¹é‡ç”Ÿæˆæ€»ç»“
        summaries = generate_summaries_batch(batch_inputs, summarizer, model_name, batch_size)
        
        # å°†æ€»ç»“ç»“æœæ˜ å°„å›åŸå§‹æ•°æ®
        for summary, idx in zip(summaries, indices):
            data_list[idx]['summary'] = summary
        
        # ä¸ºæ²¡æœ‰ç›¸å…³æ–‡æœ¬æˆ–é—®é¢˜çš„è®°å½•è®¾ç½®ç©ºæ€»ç»“
        for data in data_list:
            if 'summary' not in data:
                data['summary'] = ""
        
        # ä¿å­˜å¤„ç†åçš„æ•°æ®
        with open(output_file, 'w', encoding='utf-8') as f:
            for item in data_list:
                json.dump(item, f, ensure_ascii=False)
                f.write('\n')
        
        print(f"åŸºäºé—®é¢˜çš„æ€»ç»“å¤„ç†å®Œæˆï¼å…±å¤„ç† {len(data_list)} æ¡è®°å½•")
        print(f"å…¶ä¸­ {len(summaries)} æ¡è®°å½•ç”Ÿæˆäº†é’ˆå¯¹æ€§æ€»ç»“")
        print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
        
        # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹ç»“æœ
        print("\nç¤ºä¾‹æ€»ç»“ç»“æœ:")
        count = 0
        for item in data_list:
            if item.get('summary') and item.get('question') and count < 3:
                print(f"é—®é¢˜: {item.get('question', '')[:100]}...")
                print(f"é’ˆå¯¹æ€§æ€»ç»“: {item.get('summary', '')[:200]}...")
                print("-" * 50)
                count += 1
        
    except FileNotFoundError:
        print(f"æ–‡ä»¶æœªæ‰¾åˆ°: {input_file}")
        return
    except Exception as e:
        print(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

def main():
    """
    ä¸»å‡½æ•°
    """
    input_file = "/home/xhesica/research/outputs/20250607_extract_20250606_answer_answer_train_limit2000.json"
    
    # å¯ä»¥è°ƒæ•´æ‰¹å¤„ç†å¤§å°
    batch_size = 16  # æ ¹æ®GPUå†…å­˜è°ƒæ•´
    
    print(f"åŸºäºé—®é¢˜çš„Summaryå¤„ç†é…ç½®:")
    print(f"- è¾“å…¥æ–‡ä»¶: {input_file}")
    print(f"- æ‰¹å¤„ç†å¤§å°: {batch_size}")
    print(f"- ä½¿ç”¨GPU: {torch.cuda.is_available()}")
    print(f"- ç‰¹è‰²: æ ¹æ®æ¯ä¸ªé—®é¢˜ç”Ÿæˆé’ˆå¯¹æ€§æ€»ç»“")
    print("-" * 50)
    
    process_extraction_file(input_file, batch_size=batch_size)

if __name__ == "__main__":
    main()